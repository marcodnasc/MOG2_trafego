{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=YSLVAxgclCo\n",
    "#https://github.com/feitgemel/Open-CV/blob/main/Detect%20moving%20objects%20in%20%20fixed%20background/Detect-moving-objects-in-a-video-with-fixed-background.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053d1602",
   "metadata": {},
   "source": [
    "\n",
    "Segundo Cunha (2013), o modelo de mistura de gaussianas (MoG – Mixture of\n",
    "Gaussian) é o modelo mais usual em processamento de imagens para modelagem do fundo\n",
    "em imagens de vídeo. O método básico da mistura de gaussianas busca modelar os pixels\n",
    "do fundo através de uma função de distribuição de probabilidades aproximada por uma\n",
    "soma de K distribuições gaussianas ponderadas (KAEWTRAPULPONG; BOWDEN,\n",
    "2001). Os pesos de cada gaussiana representam a proporção de tempo em que cada cor\n",
    "esteve presente na cena (RUAS; BENSO, 2006). Como as prováveis cores do background\n",
    "tendem a ficar estáticas e permanecer por mais tempo no vídeo, os pixels de background\n",
    "são identificados ao verificar-se quais misturas de distribuições possuem peso maiores\n",
    "(MARCOMINI, 2018).\n",
    "Neste trabalho, o algoritmo utilizado para fazer a segmentação da imagem é o\n",
    "MoG2 (Mixture of Gaussian 2 ), que é uma variação do algoritmo MoG. Ele foi criado\n",
    "baseando-se em dois artigos de Zivkovic (2004 e 2006). A diferença básica entre o MoG e o\n",
    "MoG2 está no uso das distribuições gaussianas. Enquanto algoritmo MoG usa apenas um\n",
    "valor K para todos os pixels do background, algoritmo MoG2 usa um número adequado de\n",
    "distribuições gaussianas para cada pixel, proporcionando uma melhor adaptação à variação\n",
    "da cena devido às mudanças de iluminação, e também há a opção de detectar de sombras.\n",
    "Para o algoritmo de subtração de fundos (MoG2) ser iniciado, são pedidos três\n",
    "parâmetros:\n",
    "• history: define a quantidade de quadros anteriores que serão considerados para gerar\n",
    "o modelo de background;\n",
    "• varThreshold: retorna o limite de variância para o modelo de pixel correspondido.\n",
    "28 Capítulo 1. Referenciais Teóricos\n",
    "É o principal limiar no quadrado da distância de Mahalanobis para decidir se a\n",
    "amostra é bem descrita pelo modelo de background ou não;\n",
    "• detectShadows: retorna a flag de detecção de sombras, caso seja verdadeiro o algoritmo\n",
    "detecta as sombras e as marca.\n",
    "Caso esses parâmetros não sejam passados, ele será iniciado com valores padrão.\n",
    "Dependendo das condições do vídeo pode-se fazer um ajuste fino desses parâmetros\n",
    "para que a segmentação da imagem seja feita da melhor forma. O parâmetro history com\n",
    "valores baixos faz com que o algoritmo comporte-se melhor caso haja mudanças bruscas\n",
    "na luminosidade, tendo uma adaptação mais rápida, porém pode fazer com que ele fique\n",
    "muito sensível a mudanças na cena, podendo fazer com que objetos verdadeiros que se\n",
    "movem lentamente façam parte do fundo; valores altos fazem com que o modelo de fundo\n",
    "fique mais estável, mas requer mais tempo para isso, fazendo com que mudanças no fundo\n",
    "sejam calculadas de maneira mais suave, porém demorando mais para se estabilizar em\n",
    "caso de mudanças bruscas de luminosidade, podendo fazer com que o background se torne\n",
    "um objeto. O parâmetro varThreshold com valores baixos pode fazer com que parte do\n",
    "background se torne objeto, ou seja, apareçam falsos objetos na cena; já este parâmetro\n",
    "com valores mais altos pode fazer com que objetos verdadeiros façam parte do background.\n",
    "Caso o parâmetro detectShadows seja acionado, haverá um impacto no desempenho do\n",
    "algoritmo, pois vai exigir um maior processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af6124a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57a51fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para o presente trabalho, utilizarei o modelo MOG2\n",
    "#https://www.anpet.org.br/anais32/documentos/2018/Trafego%20Urbano%20e%20Rodoviario/Trafego%20em%20Vias%20Urbanas%20II/3_569_AC.pdf\n",
    "#Basicamente ele é utilizado para a verificação de trafego urbano, onde a câmera encontra-se parada enquanto os carros\n",
    "# se movimentam. Assim ele dete \n",
    "# Importa as bibliotecas necessárias: OpenCV (cv2) para processamento de vídeo e NumPy para manipulação de arrays.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "# Cria um objeto de subtração de plano de fundo utilizando o método MOG2 (Mixture of Gaussians), com um histórico de 2 frames.\n",
    "backgroundObject = cv2.createBackgroundSubtractorMOG2(history=2)\n",
    "\n",
    "#Cria um kernel 3x3 composto por uns (pixels brancos) que será usado para operações morfológicas de erosão e dilatação.\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "#Inicializa uma segunda variável de kernel como None. Isso será usado posteriormente.\n",
    "kernel2 = None\n",
    "\n",
    "#Inicia um loop infinito para processar o vídeo frame a frame.\n",
    "#Lê um frame do vídeo. A variável ret indica se a leitura do frame foi bem-sucedida, e frame contém o frame lido.\n",
    "#Se a leitura do frame falhar (quando ret é falso), o loop é interrompido.\n",
    "while True:\n",
    "    ret , frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "#Aplica o algoritmo de subtração de plano de fundo ao frame atual para obter uma máscara de plano de fundo.\n",
    "#Aplica um limiar na máscara para binarizá-la, convertendo-a em uma imagem preto e branco.\n",
    "#Aplica uma operação de erosão na máscara para remover ruídos menores.\n",
    "#Aplica uma operação de dilatação na máscara para preencher buracos e suavizar as bordas.\n",
    "\n",
    "\n",
    "    fgmask = backgroundObject.apply(frame)\n",
    "    _, fgmask = cv2.threshold(fgmask ,20 , 255 , cv2.THRESH_BINARY)\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    fgmask = cv2.dilate(fgmask,kernel2 , iterations=6  )\n",
    "\n",
    "\n",
    "    #Encontra os contornos na máscara de plano de fundo para detectar objetos em movimento.\n",
    "\n",
    "    countors, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #Faz uma cópia do frame original para desenhar retângulos e textos sobre ele.\n",
    "    frameCopy = frame.copy()\n",
    "\n",
    "    # Inicia um loop para percorrer todos os contornos encontrados.\n",
    "    #Verifica se a área do contorno é maior que 20000 pixels. Isso é feito para filtrar objetos pequenos, considerando que carros são geralmente maiores.\n",
    "\n",
    "    for cnt in countors:\n",
    "        if cv2.contourArea(cnt) > 20000:\n",
    "\n",
    "            # Obtém as coordenadas do retângulo delimitador ao redor do contorno.\n",
    "            x , y, width , height = cv2.boundingRect(cnt)\n",
    "\n",
    "            # Desenha um retângulo vermelho em volta do objeto detectado.\n",
    "            cv2.rectangle(frameCopy, (x,y), (x+width, y+ height) , (0,0,255), 2)\n",
    "\n",
    "            # Escreve um texto indicando a detecção do carro próximo ao retângulo.\n",
    "            cv2.putText(frameCopy ,\"Car detected\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.3 , (0,255,0), 1, cv2.LINE_AA)\n",
    "\n",
    "#Aplica a máscara de plano de fundo ao frame original para destacar apenas os objetos detectados.\n",
    "\n",
    "    forground = cv2.bitwise_and(frame,frame , mask = fgmask)\n",
    "\n",
    "    # Empilha horizontalmente o frame original, o frame com apenas os objetos detectados e o frame com retângulos e textos sobre os objetos.\n",
    "    stacked = np.hstack((frame,forground,frameCopy))\n",
    "\n",
    "    #Exibe a imagem empilhada com uma redução de escala de 40% na janela chamada \"stacked\".\n",
    "    cv2.imshow(\"stacked\", cv2.resize(stacked,None,fx=0.4, fy=0.4))\n",
    "\n",
    "    #cv2.imshow(\"forground\", forground)\n",
    "    #cv2.imshow(\"frameCopy\", frameCopy)\n",
    "    #cv2.imshow(\"fgmask\", fgmask)\n",
    "    #cv2.imshow(\"img\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811b4a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa as bibliotecas necessárias: OpenCV (cv2) para processamento de vídeo e NumPy para manipulação de arrays.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"india.mp4\")\n",
    "\n",
    "# Cria um objeto de subtração de plano de fundo utilizando o método MOG2 (Mixture of Gaussians), com um histórico de 2 frames.\n",
    "backgroundObject = cv2.createBackgroundSubtractorMOG2(history=2)\n",
    "\n",
    "#Cria um kernel 3x3 composto por uns (pixels brancos) que será usado para operações morfológicas de erosão e dilatação.\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "#Inicializa uma segunda variável de kernel como None. Isso será usado posteriormente.\n",
    "kernel2 = None\n",
    "\n",
    "#Inicia um loop infinito para processar o vídeo frame a frame.\n",
    "#Lê um frame do vídeo. A variável ret indica se a leitura do frame foi bem-sucedida, e frame contém o frame lido.\n",
    "#Se a leitura do frame falhar (quando ret é falso), o loop é interrompido.\n",
    "while True:\n",
    "    ret , frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "#Aplica o algoritmo de subtração de plano de fundo ao frame atual para obter uma máscara de plano de fundo.\n",
    "#Aplica um limiar na máscara para binarizá-la, convertendo-a em uma imagem preto e branco.\n",
    "#Aplica uma operação de erosão na máscara para remover ruídos menores.\n",
    "#Aplica uma operação de dilatação na máscara para preencher buracos e suavizar as bordas.\n",
    "\n",
    "\n",
    "    fgmask = backgroundObject.apply(frame)\n",
    "    _, fgmask = cv2.threshold(fgmask ,20 , 255 , cv2.THRESH_BINARY)\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    fgmask = cv2.dilate(fgmask,kernel2 , iterations=6  )\n",
    "\n",
    "\n",
    "    #Encontra os contornos na máscara de plano de fundo para detectar objetos em movimento.\n",
    "\n",
    "    countors, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    #Faz uma cópia do frame original para desenhar retângulos e textos sobre ele.\n",
    "    frameCopy = frame.copy()\n",
    "\n",
    "    # Inicia um loop para percorrer todos os contornos encontrados.\n",
    "    #Verifica se a área do contorno é maior que 20000 pixels. Isso é feito para filtrar objetos pequenos, considerando que carros são geralmente maiores.\n",
    "\n",
    "    for cnt in countors:\n",
    "        if cv2.contourArea(cnt) > 20000:\n",
    "\n",
    "            # Obtém as coordenadas do retângulo delimitador ao redor do contorno.\n",
    "            x , y, width , height = cv2.boundingRect(cnt)\n",
    "\n",
    "            # Desenha um retângulo vermelho em volta do objeto detectado.\n",
    "            cv2.rectangle(frameCopy, (x,y), (x+width, y+ height) , (0,0,255), 2)\n",
    "\n",
    "            # Escreve um texto indicando a detecção do carro próximo ao retângulo.\n",
    "            cv2.putText(frameCopy ,\"Car detected\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.3 , (0,255,0), 1, cv2.LINE_AA)\n",
    "\n",
    "#Aplica a máscara de plano de fundo ao frame original para destacar apenas os objetos detectados.\n",
    "\n",
    "    forground = cv2.bitwise_and(frame,frame , mask = fgmask)\n",
    "\n",
    "    # Empilha horizontalmente o frame original, o frame com apenas os objetos detectados e o frame com retângulos e textos sobre os objetos.\n",
    "    stacked = np.hstack((frame,forground,frameCopy))\n",
    "\n",
    "    #Exibe a imagem empilhada com uma redução de escala de 40% na janela chamada \"stacked\".\n",
    "    cv2.imshow(\"stacked\", cv2.resize(stacked,None,fx=0.4, fy=0.4))\n",
    "\n",
    "    #cv2.imshow(\"forground\", forground)\n",
    "    #cv2.imshow(\"frameCopy\", frameCopy)\n",
    "    #cv2.imshow(\"fgmask\", fgmask)\n",
    "    #cv2.imshow(\"img\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fdcef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "backgroundObject = cv2.createBackgroundSubtractorMOG2(history=2)\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "kernel2 = None\n",
    "\n",
    "while True:\n",
    "    ret , frame = cap.read()\n",
    "    if not ret :\n",
    "        break\n",
    "\n",
    "\n",
    "    fgmask = backgroundObject.apply(frame)\n",
    "    _, fgmask = cv2.threshold(fgmask ,20 , 255 , cv2.THRESH_BINARY)\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    fgmask = cv2.dilate(fgmask,kernel2 , iterations=6  )\n",
    "\n",
    "\n",
    "\n",
    "    countors, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    frameCopy = frame.copy()\n",
    "\n",
    "\n",
    "    for cnt in countors:\n",
    "        if cv2.contourArea(cnt) > 20000:\n",
    "\n",
    "            x , y, width , height = cv2.boundingRect(cnt)\n",
    "\n",
    "            cv2.rectangle(frameCopy, (x,y), (x+width, y+ height) , (0,0,255), 2)\n",
    "\n",
    "            cv2.putText(frameCopy ,\"Car detected\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.3 , (0,255,0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    forground = cv2.bitwise_and(frame,frame , mask = fgmask)\n",
    "\n",
    "    stacked = np.hstack((frame,forground,frameCopy))\n",
    "\n",
    "    cv2.imshow(\"stacked\", cv2.resize(stacked,None,fx=0.4, fy=0.4))\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30e4d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f45c23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
